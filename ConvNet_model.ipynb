{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional Neural Networks\n",
    "\"\"\"\n",
    "Differs by having convolutional layers that pick out patterns in an image\n",
    "Convolutional layers perform a \"convolution operation\"\n",
    "Apply filters that detect patterns.\n",
    "patterns can include: edges, corners, circles, squares\n",
    "As go into deeper layers, detect more complex features (eyes, scales, ears)\n",
    "As go even deeper, may detect objects such as animals\n",
    "\n",
    "A small grid will slide across image to analyse each section seperately\n",
    "This is called \"convolving\"\n",
    "\n",
    "dot product of image and filter (filter may be a 3x3 grid of random numbers to start)\n",
    "after input is convolved, end up with another image that is passed to the next layer\n",
    "These filters are pattern detectors\n",
    "example filter that detects a top edge:\n",
    "-1 -1 -1\n",
    " 1  1  1\n",
    " 0  0  0\n",
    " \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(\"Device:\",device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our neural net will set up 3 convolutional layers and 2 linear layers\n",
    "# It will run on my local NVIDIA GPU\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 5) # input, outfeatures, kernel\n",
    "        self.conv2 = nn.Conv2d(32, 64, 5)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 5)\n",
    "        \n",
    "        x = torch.randn(50,50).view(-1,1,50,50)\n",
    "        self._to_linear = None\n",
    "        self.convs(x)\n",
    "               \n",
    "        self.fc1 = nn.Linear(self._to_linear, 512)\n",
    "        self.fc2 =  nn.Linear(512, 2)\n",
    "        \n",
    "    def convs(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2,2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), (2,2))\n",
    "        x = F.max_pool2d(F.relu(self.conv3(x)), (2,2))\n",
    "        \n",
    "        # in order to determine # of features to pass to Linear layer\n",
    "        # have to flatted and get the shape of the first dimension.\n",
    "        # assign this to an internal variable to use when\n",
    "        # defining input for \n",
    "        x = torch.flatten(x, 1, -1)\n",
    "        if self._to_linear is None: \n",
    "            self._to_linear = x.shape[1]\n",
    "        return x\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.convs(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.softmax(x, dim=1) # dim 0 are the batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data\n",
    "import numpy as np\n",
    "train_data = np.load(\"train_data.npy\", allow_pickle=True)\n",
    "test_data = np.load(\"test_data.npy\", allow_pickle=True)\n",
    "\n",
    "X_train = torch.Tensor([i[0] for i in train_data]).view(-1, 50, 50)\n",
    "X_train = (X_train/255.0) # scale pixels between [0, 1]\n",
    "y_train = torch.Tensor([i[1] for i in train_data])\n",
    "\n",
    "X_test = torch.Tensor([i[0] for i in test_data]).view(-1, 50, 50)\n",
    "X_test = (X_test/255.0) # scale pixels between [0, 1]\n",
    "y_test = torch.Tensor([i[1] for i in test_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unison_shuffled_copies(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net: Net(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv3): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run training and test\n",
    "BATCH_SIZE = 100\n",
    "EPOCHS = 10\n",
    "\n",
    "def fwd_pass(X, y, train=False):\n",
    "    if train:\n",
    "        net.zero_grad()\n",
    "    outputs = net(X.to(device))\n",
    "    matches = [torch.argmax(i) == torch.argmax(j) for i,j in zip(outputs, y)]\n",
    "    acc = matches.count(True)/len(matches)\n",
    "    loss = loss_function(outputs, y.to(device))\n",
    "    \n",
    "    if train:\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return acc, loss\n",
    "\n",
    "def test(size=32):\n",
    "    random_start = np.random.randint(len(X_test)-size)\n",
    "    X, y = X_test[random_start:random_start+size], y_test[random_start:random_start+size]\n",
    "    with torch.no_grad():\n",
    "        acc, loss = fwd_pass(X.view(-1, 1, 50, 50), y)\n",
    "    return acc, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|█                                                                                 | 3/225 [00:00<00:08, 27.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv-32-64-128-lin-512-2-model-1588009585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 225/225 [00:07<00:00, 31.07it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 225/225 [00:07<00:00, 31.19it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 225/225 [00:07<00:00, 30.54it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 225/225 [00:07<00:00, 30.70it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 225/225 [00:07<00:00, 30.52it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 225/225 [00:07<00:00, 30.96it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 225/225 [00:07<00:00, 30.67it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 225/225 [00:07<00:00, 30.74it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 225/225 [00:07<00:00, 30.66it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 225/225 [00:07<00:00, 30.90it/s]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# Set up the optimizer\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "MODEL_NAME = f\"conv-32-64-128-lin-512-2-model-{int(time.time())}\"\n",
    "\n",
    "net = Net().to(device)\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "loss_function = nn.MSELoss() # mean square error loss\n",
    "\n",
    "print(MODEL_NAME)\n",
    "\n",
    "def train(batch_size=100, epochs=10, test_freq=5):\n",
    "    with open(\"convnet_logs/\"+MODEL_NAME+\".log\", \"a\") as f:\n",
    "        f.write(\"modelname,time,epoch,accuracy,loss,test_accuracy,test_loss\\n\")\n",
    "        for epoch in range(epochs):\n",
    "            # X_temp, y_temp = unison_shuffled_copies(X_train, y_train)\n",
    "            for i in tqdm(range(0, len(X_train), batch_size)):\n",
    "                batch_X = X_train[i:i+batch_size].view(-1, 1, 50, 50)\n",
    "                batch_y = y_train[i:i+batch_size]\n",
    "                acc, loss = fwd_pass(batch_X, batch_y, train=True)\n",
    "                if i % (test_freq*batch_size) == 0:\n",
    "                    test_acc, test_loss = test()\n",
    "                    f.write(\n",
    "                        (\n",
    "                        f\"{MODEL_NAME},{round(time.time(), 3)},{epoch},\"\n",
    "                        f\"{round(acc, 2)},{round(float(loss),4)},\"\n",
    "                        f\"{round(test_acc, 2)},{round(float(test_loss),4)}\\n\"\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "train()\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
